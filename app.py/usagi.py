# -*- coding: utf-8 -*-
"""OCR.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1L1eF4bhsEnX6TSdbfClgRl_CL7lQ3_jI
"""



import os
import cv2
import pandas as pd
from matplotlib import pyplot as pl
from ultralytics import YOLO
import pytesseract
import numpy as np
import gradio as gr



from weights import HELMET_MODEL_PATH, PLATE_MODEL_PATH




# Load models
helmet_model = YOLO(HELMET_MODEL_PATH)
plate_model = YOLO(PLATE_MODEL_PATH)

# ---------------- PROCESS FUNCTION ----------------
def process_frame(frame):
    img = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)
    img_out = img.copy()

    helmet_statuses = []
    plate_texts = []

    # ---- Helmet Detection ----
    helmet_results = helmet_model.predict(img, verbose=False)
    for r in helmet_results:
        for box in r.boxes:
            x1, y1, x2, y2 = map(int, box.xyxy[0])
            conf = float(box.conf[0])
            cls = int(box.cls[0])
            label = helmet_model.names[cls]

            helmet_statuses.append(label)

            color = (0, 255, 0) if label.lower() == "helmet" else (0, 0, 255)
            cv2.rectangle(img_out, (x1, y1), (x2, y2), color, 2)
            cv2.putText(img_out, f"{label} {conf:.2f}", (x1, y1 - 10),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)

    # ---- License Plate Detection ----
    plate_results = plate_model.predict(img, verbose=False)
    for r in plate_results:
        for box in r.boxes:
            x1, y1, x2, y2 = map(int, box.xyxy[0])
            plate_crop = img[y1:y2, x1:x2]
            if plate_crop.size == 0:
                continue

            gray = cv2.cvtColor(plate_crop, cv2.COLOR_BGR2GRAY)
            plate_text = pytesseract.image_to_string(
                gray,
                config='--psm 8 -c tessedit_char_whitelist=ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789'
            ).strip()

            if plate_text:
                plate_texts.append(plate_text)

            cv2.rectangle(img_out, (x1, y1), (x2, y2), (255, 255, 0), 2)
            cv2.putText(img_out, plate_text, (x1, y1 - 10),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 255, 0), 2)

    return cv2.cvtColor(img_out, cv2.COLOR_BGR2RGB), f"Helmet: {helmet_statuses}\nPlates: {plate_texts}"

# ---------------- GRADIO INTERFACE ----------------
with gr.Blocks() as demo:
    gr.Markdown("üö¶ Usagi AI (with OCR)")

    with gr.Tab("üì∑ Webcam"):
        webcam_input = gr.Image()
        webcam_output_img = gr.Image()
        webcam_output_text = gr.Textbox()
        webcam_input.stream(process_frame, [webcam_input], [webcam_output_img, webcam_output_text])

    with gr.Tab("üñºÔ∏è Image Upload"):
        img_input = gr.Image(type="numpy")
        img_output = gr.Image()
        img_text = gr.Textbox()
        img_btn = gr.Button("Process Image")
        img_btn.click(process_frame, inputs=[img_input], outputs=[img_output, img_text])

    with gr.Tab("üé• Video Upload"):
        video_input = gr.Video()
        video_output = gr.Video()
        video_text = gr.Textbox()

        def process_video(video):
            cap = cv2.VideoCapture(video)
            out_frames = []
            texts = []

            while True:
                ret, frame = cap.read()
                if not ret:
                    break
                processed_frame, txt = process_frame(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))
                out_frames.append(cv2.cvtColor(processed_frame, cv2.COLOR_RGB2BGR))
                texts.append(txt)

            cap.release()

            # Save processed video
            h, w, _ = out_frames[0].shape
            out_path = "processed_video.mp4"
            fourcc = cv2.VideoWriter_fourcc(*"mp4v")
            out = cv2.VideoWriter(out_path, fourcc, 20, (w, h))
            for f in out_frames:
                out.write(f)
            out.release()

            return out_path, "\n".join(texts)

        video_btn = gr.Button("Process Video")
        video_btn.click(process_video, inputs=[video_input], outputs=[video_output, video_text])

demo.launch(debug=True)

